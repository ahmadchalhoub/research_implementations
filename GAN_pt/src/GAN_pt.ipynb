{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the implementation of a very simple GAN (Generative Adversarial Model).\n",
    "\n",
    "This is first trial at implementing an algorithm from a research paper; in this case, 'Generative Adversarial Nets' (https://arxiv.org/pdf/1406.2661.pdf).\n",
    "\n",
    "For this implementation, I am using many resources and basically just dipping my toes in the world of applied ML, as I hope to to gain two main outcomes of this. First, I would like to improve my actual coding skills when it comes to implementing ML/DL algorithms, as I would like to eventually be able to actually read complex publications and implement them myself. This will also help me stay updated with the new advancements happening in this field. Second, it will hopefully keep me in touch with the actual technical part and prevent me from simply being an 'implementer of github projects'. \n",
    "\n",
    "PS: the actual code for this implementation is from the following Medium article: https://towardsdatascience.com/converting-deep-learning-research-papers-to-code-f-f38bbd87352f. I just made very small changes and added more detailed comments for more clarity.\n",
    "\n",
    "One thing I would also like to do is to document this progress through YouTube videos for me to both watch myself improve over time as well as help others learn and grow.\n",
    "\n",
    "I appreciate any feedback that anyone might have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch import optim\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a single image as the training dataset for the generator.\n",
    "One of the datasets used by the authors of the paper is MNIST, which I will work on using after I finish writing the basic structure and implementation of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transforms.Compose allows us to combine multiple changes that we wish to do to an input image;\n",
    "# in this case, the image is first being resized to 32x32 and then converted to a Pytorch tensor.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# size of the flattened image\n",
    "flat_img = 32*32*3\n",
    "\n",
    "img = Image.open('/home/achalhoub/dev/research_implementations/GAN_pt/input/plane_GAN.jpg')\n",
    "\n",
    "# resize the real image and convert it to a tensor\n",
    "real_img = transform(img)\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "# fake noise for image generation\n",
    "fake_img = torch.rand(1, 100)\n",
    "\n",
    "# show the image tensor\n",
    "plt.imshow(np.transpose(real_img.numpy(), (1, 2, 0)))\n",
    "print(real_img.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Discriminator, which looks at an input image and outputs a '0' of it thinks the image is fake and a '1' if it thinks the image is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a custom nn module, used for custom models.\n",
    "# a sequential model, which is made up of the input layer of\n",
    "# size 32*32*3 and a ReLU activation function and a single hidden layer\n",
    "# with 10000 nodes, and finally an output layer of size 10000 with a sigmoid \n",
    "# activation function, is instantiated.\n",
    "\n",
    "# a method for the forward pass is also created, which first flattens the\n",
    "# input image and then performs a forward pass of the image through the Discriminator.\n",
    "# this method then returns the output result that is coming from the sigmoid function.\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(flat_img, 10000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10000, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # flattens the input data\n",
    "        img = img.view(1, -1)\n",
    "        # performs the forward pass\n",
    "        out = self.linear(img)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Generator, which creates an output image tensor (fake image) using input random noise. The size of the fake image is the same size as that of the real image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a custom nn module, used for custom models.\n",
    "# a sequential model, which is made up of the input layer of\n",
    "# size 100 and a LeakyReLU activation function and two hidden layers\n",
    "# with 10000 nodes and 4000 noges, and finally an output layer of size\n",
    "# 32*32*3, is instantiated.\n",
    "\n",
    "# a method for the forward pass is also created, which first flattens the\n",
    "# input image and then performs a forward pass of the image through the Generator.\n",
    "# this method then returns the output 'fake' image produced by the generator.\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(100, 10000),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(10000, 4000),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4000, flat_img)\n",
    "        )\n",
    "\n",
    "    def forward(self, latent_space):\n",
    "        # flattens the input data\n",
    "        latent_space = latent_space.view(1, -1)\n",
    "        # performs the forward pass\n",
    "        out = self.linear(latent_space)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the models, optimizers, and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the GPU if cuda is available. otherwise use the CPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# initialize the models and assign them to the device available\n",
    "discr = Discriminator().to(device)\n",
    "gen = Generator().to(device)\n",
    "\n",
    "# initialize the optimizers for both parameters. here we use SGD\n",
    "opt_d = optim.SGD(discr.parameters(), lr=0.001, momentum=0.9)\n",
    "opt_g = optim.SGD(gen.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# initialize the loss function. the paper uses BCE (Binary Cross Entropy)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. The tutorial I am following trains the whole GAN (discriminator + generator) for 500 epochs. For each epoch of the whole GAN, the discriminator is trained for 4 epochs and the generator will be trained for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f1d0540661495cae0a90b63bd01195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define epoch values for all training loops\n",
    "GAN_epochs = 500\n",
    "discr_epochs = 4\n",
    "gen_epochs = 3\n",
    "\n",
    "# define the loop for the overall GAN training (500 epochs).\n",
    "# 'total' is used to specify the total number of expected\n",
    "# iterations (https://www.geeksforgeeks.org/python-how-to-make-a-terminal-progress-bar-using-tqdm/)\n",
    "for epoch in tqdm(range(GAN_epochs), total=GAN_epochs):\n",
    "\n",
    "    # define the loop for the discriminator training\n",
    "    for k in range(discr_epochs):\n",
    "\n",
    "        # set the gradients of all optimized 'torch.Tensor's to zero.\n",
    "        # (https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html)\n",
    "        opt_d.zero_grad()\n",
    "\n",
    "        # 'real_img.to(device) performs a Tensor device conversion. in this case,\n",
    "        # it sets the input image, real_img, on the device we previously defined (GPU).\n",
    "        # this also performs the forward pass and returns an output value from the\n",
    "        # sigmoid activation function (a value between 0 and 1).\n",
    "        out_d1 = discr(real_img.to(device))\n",
    "\n",
    "        # this measures the Binary Cross Entropy between the target and the\n",
    "        # input probability. 'out_d1' is the output of the forward pass.\n",
    "        # 'torch.ones((1, 1)).to(device)' is a 1x1 tensor of value 1, which\n",
    "        # stands for the value of the real image (remember, fake=0 & real=1).\n",
    "        # (https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\n",
    "        loss_d1 = criterion(out_d1, torch.ones((1, 1)).to(device))\n",
    "\n",
    "        # perform the backward pass (computes the gradients)\n",
    "        loss_d1.backward()\n",
    "\n",
    "        # generate a fake image from the Generator using the input latent space.\n",
    "        # 'detach' is used to return a tensor that is detached from the current\n",
    "        # graph, meaning that the tensor will never require gradient.\n",
    "        gen_output = gen(fake_img.to(device)).detach()\n",
    "\n",
    "        # same process as described above, however this time using a fake image\n",
    "        # which is created by the generator.\n",
    "        out_d2 = discr(gen_output.to(device))\n",
    "        loss_d2 = criterion(out_d2, torch.zeros((1, 1)).to(device))\n",
    "        loss_d2.backward()\n",
    "\n",
    "        # performs a parameter update based on the current gradients\n",
    "        opt_d.step()\n",
    "\n",
    "\n",
    "    # define the loop for the generator training\n",
    "    for i in range(gen_epochs):\n",
    "        opt_g.zero_grad()\n",
    "\n",
    "        # loss function for the generator used in the paper = [log(1 - D(G(z)))]\n",
    "        loss_g = torch.log(1.0 - discr(gen(fake_img.to(device)).to(device)))\n",
    "        loss_g.backward()\n",
    "\n",
    "        opt_g.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('GAN_pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f056265484383e5b66afe0560660179ace645500003f0a42b5b524fe39d5512"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
