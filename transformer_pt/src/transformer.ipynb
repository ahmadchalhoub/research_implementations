{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract the training, validation, and test data for English and German from the Multi30k dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
    "train_urls = ('train.de.gz', 'train.en.gz')\n",
    "val_urls = ('val.de.gz', 'val.en.gz')\n",
    "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n",
    "\n",
    "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
    "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
    "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand downloaded data. What format of train, val, and test data were downloaded exactly, and how much data is in it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train file paths: ', train_filepaths)\n",
    "print('Val file paths: ', val_filepaths)\n",
    "print('Test file paths: ', test_filepaths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, there is 6 files in total: 2 training files, 2 validation files, and 2 test files. Now to check what is in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open training files\n",
    "german_train_file = open(train_filepaths[0], \"r\")\n",
    "english_train_file = open(train_filepaths[1], \"r\")\n",
    "\n",
    "# Check length of german and english training data\n",
    "german_train_length = len(german_train_file.readlines())\n",
    "english_train_length = len(english_train_file.readlines())\n",
    "print('German train sentences length: ', german_train_length)\n",
    "print('English train sentences lenght: ', english_train_length)\n",
    "\n",
    "german_train_file.seek(0)\n",
    "english_train_file.seek(0)\n",
    "\n",
    "# Visualize first 2 sentences from english and german data\n",
    "print(german_train_file.readlines()[0:2])\n",
    "print(english_train_file.readlines()[0:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same steps for val and test data. From the above output, we know we have 29,000 training samples. Repeating the steps for val and test below shows that we have 1014 validation samples and 1000 testing samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open val files\n",
    "german_val_file = open(val_filepaths[0], \"r\")\n",
    "english_val_file = open(val_filepaths[1], \"r\")\n",
    "\n",
    "# Check length of german and english val data\n",
    "german_val_length = len(german_val_file.readlines())\n",
    "english_val_length = len(english_val_file.readlines())\n",
    "print('German val sentences length: ', german_val_length)\n",
    "print('English val sentences lenght: ', english_val_length)\n",
    "\n",
    "german_val_file.seek(0)\n",
    "english_val_file.seek(0)\n",
    "\n",
    "# Visualize first 2 sentences from english and german val data\n",
    "print(german_val_file.readlines()[0:2])\n",
    "print(english_val_file.readlines()[0:2])\n",
    "\n",
    "# Open test files\n",
    "german_test_file = open(test_filepaths[0], \"r\")\n",
    "english_test_file = open(test_filepaths[1], \"r\")\n",
    "\n",
    "# Check length of german and english test data\n",
    "german_test_length = len(german_test_file.readlines())\n",
    "english_test_length = len(english_test_file.readlines())\n",
    "print('German val sentences length: ', german_test_length)\n",
    "print('English val sentences lenght: ', english_test_length)\n",
    "\n",
    "german_test_file.seek(0)\n",
    "english_test_file.seek(0)\n",
    "\n",
    "# Visualize first 2 sentences from english and german test data\n",
    "print(german_test_file.readlines()[0:2])\n",
    "print(english_test_file.readlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_train_file.seek(0)\n",
    "english_train_file.seek(0)\n",
    "german_val_file.seek(0)\n",
    "english_val_file.seek(0)\n",
    "german_test_file.seek(0)\n",
    "english_test_file.seek(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load English and German tokenizers using Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lang = spacy.load(\"en_core_web_sm\")\n",
    "ger_lang = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters. I used the same ones as those used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "d_model = 512"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin building the Transformer. The first step is to build the 'Scaled Dot-Product Attention' block mentioned in the paper. This is still just the first draft; it will probably need some fixes once I get to later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProduct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProduct, self).__init__()\n",
    "        \n",
    "        # I probably don't need to initialize K, Q, and V here, since they will be passed to the \n",
    "        # scaled dot product when we call it from the MultiHeadAttention class in the forward method.\n",
    "        # Will delete the variable below later if I turn out to be right.\n",
    "        #self.queries = queries\n",
    "        #self.keys = keys\n",
    "        #self.values = values\n",
    "        self.dk = self.queries.shape[1]\n",
    "\n",
    "        # Softmax operator. 'dim' still needs to be specified\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    # Define the forward function\n",
    "    def forward(self, queries, keys, values):\n",
    "        compatibility = torch.bmm(queries, torch.transpose(keys))   # first batch MatMul operation\n",
    "        compatibility = compatibility / torch.sqrt((self.dk))       # scaling down by sqrt(dk)\n",
    "        compatibility_softmax = self.softmax(compatibility)         # normalizing using Softmax\n",
    "        output = torch.bmm(compatibility_softmax, values)           # final batch MatMul operation\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the 'Multi-Head Attention' block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, queries, keys, values):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = h\n",
    "        self.batch_num = queries.shape[0]\n",
    "        self.seq_len = queries.shape[1]\n",
    "        self.embed_len = queries.shape[2]\n",
    "        self.d_model = d_model\n",
    "        self.queries = queries\n",
    "        self.keys = keys\n",
    "        self.values = values\n",
    "        self.head_length = self.d_model/self.num_heads\n",
    "\n",
    "        # For an input, Q for example, which would originally have a shape\n",
    "        # of (N, seq_len, embed_len), it would be split up into the number of \n",
    "        # heads that we define (ex: 8). So, the new shape would be\n",
    "        # (N, seq_len, embed_len/8). This would also apply to K and V too.\n",
    "\n",
    "        # Since we are flattening batches of matrices, I'm not sure if the flattening\n",
    "        # should be done in another way. I'll come back to this later if it needs changing.\n",
    "        self.q_in = torch.flatten(self.queries).shape / self.num_heads\n",
    "        self.k_in = torch.flatten(self.keys).shape / self.num_heads\n",
    "        self.v_in = torch.flatten(self.values).shape / self.num_heads\n",
    "        \n",
    "        # For the input of each Linear layer, we would have the divided Q, K, \n",
    "        # and V calculated above. \n",
    "        self.q_linear = nn.Linear(self.q_in, self.q_in)\n",
    "        self.k_linear = nn.Linear(self.k_in, self.k_in)\n",
    "        self.v_linear = nn.Linear(self.v_in, self.v_in)\n",
    "\n",
    "        # Attention layer.\n",
    "        self.attention = ScaledDotProduct()\n",
    "\n",
    "        # This is the final Linear layer, after the outputs of all the heads\n",
    "        # from the Scaled Dot Product layer have been concatenated together. The\n",
    "        # output dimension of this layer is a hyperparameter that we define. Here\n",
    "        # we use d_model, which is 512.\n",
    "        self.output_linear = nn.Linear(self.v_in*self.num_heads, self.d_model)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # Feed the 8 heads of Q, K, and V into the linear layers in parallel, and then into the\n",
    "        # attention block. Let's say the original tensor Q has the following shape: \n",
    "        # (N, seq_len, embed_len) -> (64, 20, 512).\n",
    "        # The segment that will go into each head will be of the following size:\n",
    "        # (N, seq_len, embed_len/num_heads) -> (64, 20, 64). So we need to slice the third dimension.\n",
    "        for i in range(self.num_heads):\n",
    "\n",
    "            # The output of each of the linear layers has length -> (N*seq_len*embed_len/num_heads)\n",
    "            q_linear_output = self.q_linear(torch.flatten(queries[:, :, i*self.head_length:(i+1)*self.head_length]))\n",
    "            k_linear_output = self.k_linear(torch.flatten(keys[:, :, i*self.head_length:(i+1)*self.head_length]))\n",
    "            v_linear_output = self.v_linear(torch.flatten(values[:, :, i*self.head_length:(i+1)*self.head_length]))\n",
    "\n",
    "            # Since the three outputs computed from the linear layers above are just 1D vectors of length\n",
    "            # (N*seq_len*embed_len/num_heads), and the ScaledDotProduct forward method expects 3D tensors,\n",
    "            # I will reshape the 1D vectors into 3D tensors of shape (N, seq_len, embed_len/num_heads)\n",
    "            q_reshaped_output = torch.reshape(q_linear_output, (self.batch_num, self.seq_len, self.embed_len))\n",
    "            k_reshaped_output = torch.reshape(k_linear_output, (self.batch_num, self.seq_len, self.embed_len))\n",
    "            v_reshaped_output = torch.reshape(v_linear_output, (self.batch_num, self.seq_len, self.embed_len))\n",
    "\n",
    "            # Feed reshaped Q, K, and V into ScaledDotProduct layer\n",
    "            sdp_output = self.attention.forward(q_reshaped_output, k_reshaped_output, v_reshaped_output)         \n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe19fb5bed516e6ac74a9b255f69d3cfb16eeb4b5a81b7a48fdeb18da73b6471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
